Definition of caching:
- "official": RFC 2616 (HTTP/1.1) defines "cache" as local store for response messages
- "loose": Moving the content closer to client/user

The meat of this section are the goals of caching:

1. reduce client-side latency between request and response time:
Most important goal of caching. Brings good effects for user and developer. Getting content faster leads to spending more time on the site.

2. reduce the load on the network, LAN or Internet, by avoiding repeated transmissions of same response:
This goal primarily affects the network. We transfer only important information, so we avoid resending the content, which the user got from a "closer" location).
This leads to less congestion hence less packet losses/drops hence better performance for every network user.

3. reduce the load on the server by having an intermediary between client and origin server which handles requests instead:
This gives the server more room to handle more requests.
This leads to improvements not only on the application-layer (client) but also transport-layer where less TCP-connections get refused as a result of long waiting in the waiting-queue.
Pending requests benefit also in this case from a shorter delay.
